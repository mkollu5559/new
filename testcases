##########################################################################
#  Description : LANDING TO CONFORM COMMON SCRIPT: V1                    #
#  Purpose     : Moves data from Landing to Conform for all data domains #
#  Supports    : No partition and partition                              #
#  Author      : Mani Ravuri                                             #
##########################################################################
import json
import logging
import sys
from datetime import datetime, timezone

import boto3, botocore
import inspect
from awsglue.context import GlueContext
from awsglue.dynamicframe import DynamicFrame
from awsglue.job import Job
from awsglue.transforms import ApplyMapping
from awsglue.utils import getResolvedOptions

from common_utils import common_util
from pyspark.sql import SparkSession
from pyspark.sql.functions import lit, col

args = getResolvedOptions(
    sys.argv,
    [
        "JOB_NAME",
        "BUCKET_NAME",
        "ETL_CATALOG_ID",
        "DA_CATALOG_ID",
        "incr_ingest_timestamp",
        "refresh_type",
        "upd_record_count",
    ],
)
JOB_NAME = args["JOB_NAME"]

JOB_RUN_ID = args["JOB_RUN_ID"]
BUCKET_NAME = args["BUCKET_NAME"]
ETL_CATALOG_ID = args["ETL_CATALOG_ID"]
DA_CATALOG_ID = args["DA_CATALOG_ID"]
incr_ingest_timestamp = args["incr_ingest_timestamp"]
refresh_type = args["refresh_type"]
upd_record_count = args["upd_record_count"]
s3client = boto3.client("s3")

glue_client = boto3.client("glue", "us-east-1")


spark = (
    SparkSession.builder.appName(JOB_NAME)
    .config(
        "hive.metastore.client.factory.class",
        "com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory",
    )
    .config("hive.metastore.glue.catalogid", DA_CATALOG_ID)
    .config("spark.sql.parquet.outputTimestampType", "TIMESTAMP_MICROS")
    .config("spark.sql.parquet.int96RebaseModeInRead", "CORRECTED")
    .config("spark.sql.parquet.int96RebaseModeInWrite", "CORRECTED")
    .config("spark.sql.parquet.datetimeRebaseModeInRead", "CORRECTED")
    .config("spark.sql.parquet.datetimeRebaseModeInWrite", "CORRECTED")
    .enableHiveSupport()
    .getOrCreate()
)
spark.conf.set("spark.sql.sources.partitionOverwriteMode", "dynamic")
spark_context = spark.sparkContext
glue_context = GlueContext(spark_context)
logger = logging.getLogger()
logger.addHandler(logging.StreamHandler(sys.stdout))
logger.setLevel(logging.INFO)
job = Job(glue_context)
job.init(args["JOB_NAME"], args)

start_time = datetime.now(timezone.utc)
src_offset_dict = {}
inventory_job_names = ["job_gov_conform_oss_oss_export_object_metric","job_gov_conform_oss_oss_export_usm_object_metric"]


logger.info(f"upd_record_count : {upd_record_count}")


def add_new_partition(
    glue_client: botocore.client.BaseClient,
    database_name: str,
    table_name: str,
    partition: str,
):
    try:
        response = glue_client.get_table(DatabaseName=database_name, Name=table_name)

        if response["Table"]:
            # the table exists
            if response["Table"]["PartitionKeys"]:
                # table is partitioned
                storage_descriptor = response["Table"]["StorageDescriptor"]
                partition_key = response["Table"]["PartitionKeys"][0]["Name"]
                storage_descriptor["Location"] += f"{partition_key}={partition}/"
                response = glue_client.create_partition(
                    DatabaseName=database_name,
                    TableName=table_name,
                    PartitionInput=dict(
                        Values=[partition], StorageDescriptor=storage_descriptor
                    ),
                )
                logger.info(
                    f"Added partition {partition} to the table {database_name}.{table_name} "
                )
            else:
                logger.info(
                    f"The table {database_name}.{table_name} is not partitioned"
                )

        else:
            logger.info(f"The table {database_name}.{table_name} is does not exists")

    except glue_client.exceptions.EntityNotFoundException:
        # the table or database does not exists
        # run the crawler to create the table
        logger.error(f"The table {database_name}.{table_name} was not found")
        logger.error(
            common_util.mattermost_logger_msg(
                "Table not found . Error in {}: {}:{}".format(
                    inspect.currentframe().f_code.co_name, JOB_NAME, table_name
                )
            )
        )

    except Exception as ex:
        logger.error(
            common_util.mattermost_logger_msg(
                "Error in {}: {}:{}".format(
                    inspect.currentframe().f_code.co_name, JOB_NAME, ex
                )
            )
        )
        raise Exception(
            f"Exception while adding partition {partition} to table {database_name}.{table_name}",
            ex,
        )


def backup_conform_master(job_details):
    if JOB_NAME in inventory_job_names:
        return
    backup_time = datetime.now(timezone.utc).strftime("%Y%m%d%H%M%S")
    logger.info(
        f"received refresh type as full, taking conform master back up for date {backup_time}"
    )
    logger.info("started taking conform back up")
    s3_conform_master = job_details["Target_S3_Folder_Name"]["Master"]
    values = s3_conform_master.split("/")
    bucket = values[2]
    actual_prefix = "/".join(values[len(values) - 3:]) + "/"
    backup_prefix = "/".join(values[: len(values) - 2])
    table = values[-1]
    s3_conform_master_backup = (
        f"{backup_prefix}/MasterBackup/{table}/backup_timestamp={backup_time}"
    )

    try:
        response = s3client.list_objects_v2(
            Bucket=bucket, MaxKeys=1, Prefix=actual_prefix
        )
        if response["KeyCount"] == 1:
            # read from conform master
            conform_master_df = spark.read.format("parquet").load(s3_conform_master)
            # write to conform master back up
            conform_master_df.write.mode("overwrite").format("parquet").option(
                "compression", "snappy"
            ).save(s3_conform_master_backup)
            # delete from conform master
            more_objects = True
            found_token = True
            while more_objects:
                if found_token:
                    response = s3client.list_objects_v2(
                        Bucket=bucket, Prefix=actual_prefix, Delimiter="/"
                    )
                else:
                    response = s3client.list_objects_v2(
                        Bucket=bucket,
                        ContinuationToken=found_token,
                        Prefix=actual_prefix,
                        Delimiter="/",
                    )
                for source in response["Contents"]:
                    if source["Key"].endswith(".parquet"):
                        s3client.delete_object(Bucket=bucket, Key=source["Key"])
                # Now check there is more objects to list
                if "NextContinuationToken" in response:
                    found_token = response["NextContinuationToken"]
                    more_objects = True
                else:
                    more_objects = False
            logger.info("completed taking conform back up")
        else:
            logger.info("s3 path doesnt exist to take back up")
    except Exception as ex:
        common_util.update_job_table(
            job_details,
            start_time,
            0,
            0,
            "Failed",
            "E001",
            "Exception while taking master table backup",
            datetime.now(timezone.utc),
            JOB_RUN_ID,
            src_offset_dict,
            BUCKET_NAME,
            glue_context,
            spark,
            refresh_type=refresh_type,
        )
        logger.error(
            f"Exception while taking back up for conform master table: {table}"
        )
        raise Exception(
            "Exception while taking back up for conform master table: ", table, ex
        )


def upd_del_records_check(delta_df, master_df, join_column):
    """ """
    ## Check logic
    upd_df = delta_df.where(delta_df.CTL_ETL_DML_FLG == "U").select(join_column)
    del_df = delta_df.where(delta_df.CTL_ETL_DML_FLG == "D").select(join_column)

    delete_chk_count = (
        del_df.join(master_df, join_column, "left")
        .filter(master_df[join_column].isNull())
        .count()
    )
    update_chk_count = (
        upd_df.join(master_df, join_column, "left")
        .filter(master_df[join_column].isNull())
        .count()
    )

    if (delete_chk_count > 0) or (update_chk_count > 0):
        message = """Delta load has {del_cnt} - Delete records; {upd_cnt} - Update records without any prior records in the master data
                  """.format(
            del_cnt=delete_chk_count, upd_cnt=update_chk_count
        )
        logger.warning(
            common_util.mattermost_logger_msg(
                "Warning in {}: {}:{}".format(
                    inspect.currentframe().f_code.co_name, JOB_NAME, message
                )
            )
        )
        logger.info(message)


def check_file_exists(file_path, ends_with: str):
    """

    :param ends_with:
    :param file_path: s3 path to check if files exists
    :return: true if files exist else false
    """
    bucket = file_path.split("//")[-1].split("/")[0]
    prefix = "/".join(file_path.split("//")[-1].split("/")[1:]) + "/"
    response = s3client.list_objects_v2(Bucket=bucket, MaxKeys=1, Prefix=prefix)
    return (
        True
        if response["KeyCount"] == 1
        and response["Contents"][0]["Key"].endswith(ends_with)
        else False
    )


def parse_schema(SourceSchema, TargetSchema):
    """

    :param SourceSchema: oss schema
    :param TargetSchema: etl/spark schema
    :return: [{
               'name': '{col_name}',
               'src_type': '{src_schema_type}',
               'tgt_type': '{target_schema_type}'
             }]
    """
    build_schema_details = []
    if len(SourceSchema) == len(TargetSchema):
        for i in range(0, len(SourceSchema)):
            match_found = 0
            for ii in range(0, len(TargetSchema)):
                if SourceSchema[i]["name"] == TargetSchema[ii]["name"]:
                    match_found = 1
                    col_dict = {
                        "name": SourceSchema[i]["name"],
                        "src_type": SourceSchema[i]["Data_type"],
                        "tgt_type": TargetSchema[ii]["Data_type"],
                    }
                    build_schema_details.append(col_dict)
                    break
            if match_found == 0:
                logger.error(
                    common_util.mattermost_logger_msg(
                        "Target Column name not found in config.json file for source column.Error in {}: {}:{}".format(
                            inspect.currentframe().f_code.co_name,
                            JOB_NAME,
                            SourceSchema[i]["name"],
                        )
                    )
                )
                raise Exception(
                    "Error: Target Column name not found in config.json file for source column ",
                    SourceSchema[i]["name"],
                )
    else:
        logger.error(
            common_util.mattermost_logger_msg(
                "Error in {}: {}:{}".format(
                    inspect.currentframe().f_code.co_name,
                    JOB_NAME,
                    "Schema mismatch in config.json file",
                )
            )
        )
        raise Exception("Error: Schema mismatch in config.json file ")
    return build_schema_details


def merge_data_frames(master_dyf, delta_dyf, join_column):
    """

    :param master_dyf: conform master dynamic data frame
    :param delta_dyf:  landing incremental dynamic data frame
    :param join_column: join column used to merge master_dyf and delta_dyf
    :return: merged dynamic data frame
    """

    master_df = master_dyf.toDF().drop("CTL_BTCH_ID", "INCR_INGEST_TIMESTAMP",
                                       "CTL_ETL_LOAD_DT_TM")  # added CTL_ETL_LOAD_DT_TM
    delta_df = delta_dyf.toDF()

    # # Check if update/delete records have prior records in master df.
    # upd_del_records_check(delta_df, master_df, join_column)
    # select only deleted records from delta
    del_df = delta_df.where(delta_df.CTL_ETL_DML_FLG == "D")
    # select only inserted/updated records from delta
    ins_upd_df = delta_df.where(delta_df.CTL_ETL_DML_FLG != "D")
    # with deleted records from delta, read conform master and change the CTL_ETL_DML_FLG flag to D
    # (since deleted records doesnt contain all details required)
    upd_del_df = (
        master_df.join(del_df, [join_column])
        .select(master_df["*"], "CTL_BTCH_ID", "INCR_INGEST_TIMESTAMP",
                "CTL_ETL_LOAD_DT_TM")  # added CTL_ETL_LOAD_DT_TM
        .withColumn("CTL_ETL_DML_FLG", lit("D"))
    )
    # create dynamic data frame for insert/update records
    delta_ins_upd_dyf = DynamicFrame.fromDF(
        ins_upd_df, glue_context, "transformation_ctx"
    )
    # create dynamic data frame for delete records in delta
    delta_del_dyf = DynamicFrame.fromDF(upd_del_df, glue_context, "transformation_ctx")
    # run mergeDynamicFrame on master_dyf and insert/updated dyf
    merged_dyf = master_dyf.mergeDynamicFrame(delta_ins_upd_dyf, [join_column])
    # run mergeDynamicFrame on merged_dyf and delete dyf
    if delta_del_dyf.count() > 1:
        merged_dyf = merged_dyf.mergeDynamicFrame(delta_del_dyf, [join_column])
    # from final merged dyf join with delta dyf to get complete delta with updated values for delete records
    merged_df = merged_dyf.toDF()
    delta_upd_dyf = DynamicFrame.fromDF(
        merged_df.join(delta_df, [join_column]).select(merged_df["*"]),
        glue_context,
        "transformation_ctx",
    )
    return merged_dyf, delta_upd_dyf


def update_schema(dyf, schema_details):
    """

    :param dyf: dynamic data frame
    :param schema_details: schema details with source type and target type
    :return: dynamic data frame with target type
    """
    schema_mappings = [
        (i["name"], i["src_type"], i["name"], i["tgt_type"]) for i in schema_details
    ]
    return ApplyMapping.apply(frame=dyf, mappings=schema_mappings)


def update_schema_after_merge(dyf, schema_details):
    """

    :param dyf: dynamic data frame
    :param schema_details: schema details
    :return: updated dynamic data frame after merge
    : NOTE: this method can be ignored in code if rdbms sync is sending data types correctly
    """
    schema_mappings = [
        (i["name"], i["tgt_type"], i["name"], i["tgt_type"]) for i in schema_details
    ]
    return ApplyMapping.apply(frame=dyf, mappings=schema_mappings)


def transform(record, agg_col, groupBy_cols):
    grp_arr = ["{0} = '{1}'".format(c, record[c]) for c in groupBy_cols]
    grp_agg = " and ".join(grp_arr)
    date_in_str = ",".join(
        map(lambda s: "'{}'".format(s), record["{}".format(agg_col)])
    )
    return "({0} and {1} in ({2}))".format(grp_agg, agg_col, date_in_str)


def full_load(job_details, schema_details):
    """

    :param job_details: job details
    :param schema_details: schema details
    :return: completes full load based on job details and schema details for both
    partitioned and non-partitioned tables (insert conform master and history)
    """
    logger.info(
        common_util.mattermost_logger_msg(
            "Full Load Started for partition  {}: {}: Refresh type received {}".format(
                incr_ingest_timestamp, JOB_NAME, refresh_type
            )
        )
    )
    ctl_btch_id = ""
    da_database = job_details["Source_Crawler_DB_Name"]
    da_table = job_details["Source_Crawler_Table_Name"]["Landing_Data_Object"][0]
    conform_table = job_details["Source_Crawler_Table_Name"]["Master_Data_Object"][0]
    src_offset_dict[da_table] = incr_ingest_timestamp

    if 'MA_DataSync' in job_details.keys():
        maa_source = job_details["MA_DataSync"]
        logger.info(f"maa_source={maa_source}")
    else:
        maa_source = 'Y'

    isInventory = False
    if JOB_NAME in inventory_job_names:
        isInventory = True
    try:
        logger.info(f"Started reading from d&a landing for {da_table}")
        # read full load data from d&a master
        # if "cdo_mbr_accumr_dtl" in conform_table:
        if maa_source.upper() == 'Y':
            bucket_env = db_env = conform_table.split("_")[2]
            db_tablename = "_".join(conform_table.split("_")[4:]).lower()
            if db_env == 'dev':
                db_env = '_dev'
            if db_env == 'qa':
                bucket_env = 'test'
                db_env = '_qa'
            if db_env == 'prod':
                db_env = ''

            domain = da_database.replace("_gov", "")
            madatasyncdatapath = f"s3://silverton-maa-raw-internal-data-{domain}-{bucket_env}/madatasync/oss_export{db_env}_v/{db_tablename}/incr_ingest_timestamp={incr_ingest_timestamp}"
            temp_df = spark.read.parquet(madatasyncdatapath)
            temp_df.printSchema()
            full_df = temp_df.withColumn("incr_ingest_timestamp", lit(incr_ingest_timestamp))
            logger.info(f"Reading from madatasync {da_table} is completed: {full_df.count()}")
        else:
            full_df = spark.sql(
                f"select * from {da_database}.{da_table} where incr_ingest_timestamp='{incr_ingest_timestamp}'"
            )

        logger.info(f"Completed reading from d&a landing for {da_table}")
        # get batch id from data frame
        ctl_btch_id = full_df.select("ctl_btch_id").first()["ctl_btch_id"]
        # convert full load spark data frame to dynamic data frame
        full_dyf = DynamicFrame.fromDF(full_df, glue_context, "full_dyf")
    except Exception as ex:
        common_util.update_job_table(
            job_details,
            start_time,
            0,
            0,
            "Failed",
            "E001",
            "Unable to read from table",
            datetime.now(timezone.utc),
            JOB_RUN_ID,
            src_offset_dict,
            BUCKET_NAME,
            glue_context,
            spark,
            ctl_btch_id,
            refresh_type=refresh_type,
        )

        logger.error(
            common_util.mattermost_logger_msg(
                "Unable to read from d&a landing table in {}: {}:{}".format(
                    inspect.currentframe().f_code.co_name, JOB_NAME, ex
                )
            )
        )
        raise Exception("Unable to read from crawler table: ", da_table, ex)

    try:
        # run update schema on full load dynamic data frame
        full_upd_schema_dyf = update_schema(full_dyf, schema_details)
        # after updating schema convert dynamic data frame to spark data frame
        full_upd_schema_df = full_upd_schema_dyf.toDF()
    except Exception as ex:
        common_util.update_job_table(
            job_details,
            start_time,
            0,
            0,
            "Failed",
            "E001",
            "Unable to convert source schema to target schema",
            datetime.now(timezone.utc),
            JOB_RUN_ID,
            src_offset_dict,
            BUCKET_NAME,
            glue_context,
            spark,
            ctl_btch_id,
            refresh_type=refresh_type,
        )

        logger.error(
            common_util.mattermost_logger_msg(
                "Error in {}: {}:{}".format(
                    inspect.currentframe().f_code.co_name, JOB_NAME, ex
                )
            )
        )
        raise Exception("Unable to update schema for : ", da_table, ex)

    rec_cnt = full_dyf.count()
    parts = 100
    if rec_cnt > 10000000 and rec_cnt < 100000000:
        parts = 200
    elif rec_cnt >= 100000000:
        parts = 300

    if isInventory:
        logger.info(
            f"Not required to write to conform master for inventory file table {da_table}"
        )
    else:
        try:
            logger.info(f"started writing to conform master for {da_table}")
            backup_conform_master(job_details)
            if job_details["Partition_Key"]:
                # if table contains partitions convert partition columns to string
                for col in job_details["Partition_Key"]:
                    full_upd_schema_df = full_upd_schema_df.withColumn(
                        col.lower(),
                        full_upd_schema_df["{0}".format(col)].cast("string"),
                    )
                # write to conform master
                full_upd_schema_df.repartition(parts).write.partitionBy(
                    job_details["Partition_Key"]
                ).mode("overwrite").format("parquet").option(
                    "compression", "snappy"
                ).save(
                    job_details["Target_S3_Folder_Name"]["Master"]
                )
            else:
                # write to conform master
                full_upd_schema_df.repartition(parts).write.mode("overwrite").format(
                    "parquet"
                ).option("compression", "snappy").save(
                    job_details["Target_S3_Folder_Name"]["Master"]
                )
                logger.info(f"completed writing to conform master for {da_table}")
        except Exception as ex:
            common_util.update_job_table(
                job_details,
                start_time,
                0,
                0,
                "Failed",
                "E002",
                "Unable to write to target object",
                datetime.now(timezone.utc),
                JOB_RUN_ID,
                src_offset_dict,
                BUCKET_NAME,
                glue_context,
                spark,
                ctl_btch_id,
                refresh_type=refresh_type,
            )
            logger.error(
                "Unable to write to target: {0}".format(
                    job_details["Target_S3_Folder_Name"]["Master"]
                )
            )
            raise Exception(
                "Unable to write to target: ",
                job_details["Target_S3_Folder_Name"]["Master"],
                ex,
            )

    # write to conform history
    update_history(full_upd_schema_df, job_details, isInventory, ctl_btch_id)

    # update job status in job execution table to complete
    common_util.update_job_table(
        job_details,
        start_time,
        rec_cnt,
        rec_cnt,
        "Success",
        "",
        "",
        datetime.now(timezone.utc),
        JOB_RUN_ID,
        src_offset_dict,
        BUCKET_NAME,
        glue_context,
        spark,
        ctl_btch_id,
        refresh_type=refresh_type,
    )


def incremental_load(job_details, schema_details):
    """

    :param job_details:
    :param schema_details:
    :return: completes incremental load based on job details and schema details for
    both partitioned and non-partitioned tables (overwrite conform master and append conform history)
    """
    logger.info("inside incremental load")
    ctl_btch_id = ""
    da_database = job_details["Source_Crawler_DB_Name"]
    etl_database = job_details["Source_Crawler_DB_Name"]
    landing_table = job_details["Source_Crawler_Table_Name"]["Landing_Data_Object"][0]
    conform_table = job_details["Source_Crawler_Table_Name"]["Master_Data_Object"][0]
    src_offset_dict[landing_table] = incr_ingest_timestamp

    if 'MA_DataSync' in job_details.keys():
        maa_source = job_details["MA_DataSync"]
        logger.info(f"maa_source={maa_source}")
    else:
        maa_source = 'Y'

    isInventory = False
    isControlTable = False
    if JOB_NAME in inventory_job_names:
        isInventory = True
    if 'fhir_cdo_' in JOB_NAME or 'fhir_ctl_' in JOB_NAME:
        isControlTable = True

    try:
        logger.info(f"Started reading from d&a landing for {landing_table}")
        # read incremental data from d&a and create spark data frame
        # if "cdo_mbr_accumr_dtl" in conform_table:
        if maa_source.upper() == 'Y':
            bucket_env = db_env = conform_table.split("_")[2]
            db_tablename = "_".join(conform_table.split("_")[4:]).lower()
            if db_env == 'dev':
                db_env = '_dev'
            if db_env == 'qa':
                bucket_env = 'test'
                db_env = '_qa'
            if db_env == 'prod':
                db_env = ''
            domain = da_database.replace("_gov", "")
            madatasyncdatapath = f"s3://silverton-maa-raw-internal-data-{domain}-{bucket_env}/madatasync/oss_export{db_env}_v/{db_tablename}/incr_ingest_timestamp={incr_ingest_timestamp}"
            temp_df = spark.read.parquet(madatasyncdatapath)
            temp_df.printSchema()
            landing_incr_df = temp_df.withColumn("incr_ingest_timestamp", lit(incr_ingest_timestamp))
            logger.info(f"Reading from madatasync {landing_table} is completed")
        else:
            landing_incr_df = spark.sql(
                f"select * from {da_database}.{landing_table} where incr_ingest_timestamp='{incr_ingest_timestamp}'"
            )
        logger.info(f"Completed reading from d&a landing for {landing_table}")
        # get batch id from delta df
        ctl_btch_id = landing_incr_df.select("ctl_btch_id").first()["ctl_btch_id"]
        # convert incremental spark data frame to dynamic data frame
        landing_incr_dyf = DynamicFrame.fromDF(
            landing_incr_df, glue_context, "landing_incr_dyf"
        )
        # run update schema on incremental data frame
        landing_incr_dyf = update_schema(landing_incr_dyf, schema_details)
    except Exception as ex:
        common_util.update_job_table(
            job_details,
            start_time,
            0,
            0,
            "Failed",
            "E001",
            "Unable to read from table",
            datetime.now(timezone.utc),
            JOB_RUN_ID,
            src_offset_dict,
            BUCKET_NAME,
            glue_context,
            spark,
            ctl_btch_id,
            refresh_type=refresh_type,
        )

        logger.error(
            common_util.mattermost_logger_msg(
                "Unable to read from d&a landing table : Error in {}: {}:{}".format(
                    inspect.currentframe().f_code.co_name, JOB_NAME, ex
                )
            )
        )
        raise Exception(
            "Unable to read from d&a landing table, table name : ", landing_table, ex
        )

    if not isInventory and not isControlTable: #no master for inventory and control table
        try:
            # read full data from conform master
            logger.info(f"Started reading from Conform master for {conform_table}")
            conform_current_dyf = common_util.create_data_frame(
                etl_database,
                conform_table,
                ETL_CATALOG_ID,
                glue_context,
                transformationCtx=False,
            )
            logger.info(f"Completed reading from Conform master for {conform_table}")
        except Exception as ex:
            common_util.update_job_table(
                job_details,
                start_time,
                0,
                0,
                "Failed",
                "E001",
                "Unable to read from table",
                datetime.now(timezone.utc),
                JOB_RUN_ID,
                src_offset_dict,
                BUCKET_NAME,
                glue_context,
                spark,
                ctl_btch_id,
                refresh_type=refresh_type,
            )

            logger.error(
                common_util.mattermost_logger_msg(
                    "Unable to read from conform master table.Error in {}: {}:{}".format(
                        inspect.currentframe().f_code.co_name, JOB_NAME, ex
                    )
                )
            )
            raise Exception(
                "Unable to read from conform master table, table name : ",
                conform_table,
                ex,
            )

        if job_details["Partition_Key"]:
            try:
                incr_upd_df = landing_incr_dyf.toDF()
                # convert partition columns to string (since conform master contain them as string)
                for col in job_details["Partition_Key"]:
                    incr_upd_df = incr_upd_df.withColumn(
                        col.lower(), incr_upd_df["{0}".format(col)].cast("string")
                    )
                delta_dyf = DynamicFrame.fromDF(incr_upd_df, glue_context, "delta_dyf")
                logger.info("Merge data frames started")
                # merge data frame returns full master dynamic data frame and incremental dynamic data frame
                # master dyf goes to conform master, incremental dyf goes to conform history
                final_dyf, delta_upd_dyf = merge_data_frames(
                    conform_current_dyf, delta_dyf, job_details["Joining_Condition"]
                )
                logger.info("Merge data frames complete")

                # below code can be ignored (test it before remove it)
                for i in schema_details:
                    if i["name"] in job_details["Partition_Key"]:
                        i["tgt_type"] = "STRING"
                final_dyf = update_schema_after_merge(final_dyf, schema_details)

            except Exception as ex:
                common_util.update_job_table(
                    job_details,
                    start_time,
                    0,
                    0,
                    "Failed",
                    "E003",
                    "Unable to merge master and incremental",
                    datetime.now(timezone.utc),
                    JOB_RUN_ID,
                    src_offset_dict,
                    BUCKET_NAME,
                    glue_context,
                    spark,
                    ctl_btch_id,
                    refresh_type=refresh_type,
                )

                logger.error(
                    common_util.mattermost_logger_msg(
                        "Error in {}: {}:{}".format(
                            inspect.currentframe().f_code.co_name, JOB_NAME, ex
                        )
                    )
                )
                raise Exception(
                    "Unable to merge master and incremental for job: ",
                    job_details["Job_Name"],
                    ex,
                )

            try:
                rec_cnt = final_dyf.count()
                parts = 100
                if rec_cnt > 10000000 and rec_cnt < 100000000:
                    parts = 200
                elif rec_cnt >= 100000000:
                    parts = 300
                logger.info("Started writing to conform master temp")
                s3_temp_path = f"{job_details['Target_S3_Folder_Name']['Master']}/temp"
                final_dyf.toDF().repartition(parts).write.partitionBy(
                    job_details["Partition_Key"]
                ).mode("overwrite").format("parquet").option(
                    "compression", "snappy"
                ).save(
                    s3_temp_path
                )

                # from temp copy to actual s3 path
                common_util.update_conform_master(s3_temp_path)

                logger.info("Completed writing to conform master")
            except Exception as ex:
                common_util.update_job_table(
                    job_details,
                    start_time,
                    0,
                    0,
                    "Failed",
                    "E002",
                    "Unable to write to target object",
                    datetime.now(timezone.utc),
                    JOB_RUN_ID,
                    src_offset_dict,
                    BUCKET_NAME,
                    glue_context,
                    spark,
                    ctl_btch_id,
                    refresh_type=refresh_type,
                )

                logger.error(
                    common_util.mattermost_logger_msg(
                        "Error in {}: {}:{}".format(
                            inspect.currentframe().f_code.co_name, JOB_NAME, ex
                        )
                    )
                )
                raise Exception(
                    "Unable to write to target: ",
                    job_details["Target_S3_Folder_Name"]["Master"],
                    ex,
                )
        else:
            try:
                logger.info("Merge data frames started")
                # merge data frame returns full master dynamic data frame and incremental dynamic data frame
                # master dyf goes to conform master, incremental dyf goes to conform history
                final_dyf, delta_upd_dyf = merge_data_frames(
                    conform_current_dyf,
                    landing_incr_dyf,
                    job_details["Joining_Condition"],
                )
                logger.info("Merge data frames complete")
                final_dyf.toDF()
                # Below code make sure no null data types are there in data frames that we are going to write to s3
                # Since parquet format doesnt support null data types
                final_dyf = update_schema_after_merge(final_dyf, schema_details)
                delta_upd_dyf = update_schema_after_merge(delta_upd_dyf, schema_details)
            except Exception as ex:
                common_util.update_job_table(
                    job_details,
                    start_time,
                    0,
                    0,
                    "Failed",
                    "E003",
                    "Unable to merge master and incremental",
                    datetime.now(timezone.utc),
                    JOB_RUN_ID,
                    src_offset_dict,
                    BUCKET_NAME,
                    glue_context,
                    spark,
                    ctl_btch_id,
                    refresh_type=refresh_type,
                )

                logger.error(
                    common_util.mattermost_logger_msg(
                        "Error in {}: {}:{}".format(
                            inspect.currentframe().f_code.co_name, JOB_NAME, ex
                        )
                    )
                )
                raise Exception(
                    "Unable to merge master and incremental for job: ",
                    job_details["Job_Name"],
                    ex,
                )

            try:
                rec_cnt = final_dyf.count()
                parts = 100
                if rec_cnt > 10000000 and rec_cnt < 100000000:
                    parts = 200
                elif rec_cnt >= 100000000:
                    parts = 300

                logger.info("Started writing to conform master temp")
                # write to temp directory
                s3_temp_path = f"{job_details['Target_S3_Folder_Name']['Master']}/temp"
                final_dyf.toDF().repartition(parts).write.mode("overwrite").format(
                    "parquet"
                ).option("compression", "snappy").save(s3_temp_path)

                # from temp copy to actual s3 path
                common_util.update_conform_master(s3_temp_path)

                logger.info("Completed writing to conform master")
            except Exception as ex:
                common_util.update_job_table(
                    job_details,
                    start_time,
                    0,
                    0,
                    "Failed",
                    "E002",
                    "Unable to write to target object",
                    datetime.now(timezone.utc),
                    JOB_RUN_ID,
                    src_offset_dict,
                    BUCKET_NAME,
                    glue_context,
                    spark,
                    ctl_btch_id,
                    refresh_type=refresh_type,
                )

                logger.error(
                    common_util.mattermost_logger_msg(
                        "Unable to write to target .Error in {}: {}:{}".format(
                            inspect.currentframe().f_code.co_name, JOB_NAME, ex
                        )
                    )
                )
                raise Exception(
                    "Unable to write to target: ",
                    job_details["Target_S3_Folder_Name"]["Master"],
                    ex,
                )

        target_count = update_history(
            delta_upd_dyf.toDF(), job_details, False, ctl_btch_id
        )

        common_util.update_job_table(
            job_details,
            start_time,
            landing_incr_dyf.count(),
            target_count,
            "Success",
            "",
            "",
            datetime.now(),
            JOB_RUN_ID,
            src_offset_dict,
            BUCKET_NAME,
            glue_context,
            spark,
            ctl_btch_id,
            refresh_type=refresh_type,
        )
    else:
        # write to conform history and update partition in glue catalog
        # for inventory job update_history will return 0 as count
        if isInventory:
         #create json file
            target_count = update_history(
            landing_incr_dyf.toDF(), job_details, True, ctl_btch_id
        )
        else: #for ctl table create parquet file
            target_count = update_history(
                landing_incr_dyf.toDF(), job_details, False, ctl_btch_id
            )

        # target_count = landing_incr_dyf.count()
        common_util.update_job_table(
            job_details,
            start_time,
            target_count,
            target_count,
            "Success",
            "",
            "",
            datetime.now(),
            JOB_RUN_ID,
            src_offset_dict,
            BUCKET_NAME,
            glue_context,
            spark,
            ctl_btch_id,
            refresh_type=refresh_type,
        )


def incremental_load_clm_history(job_details, schema_details):
    """

    :param job_details:
    :param schema_details:
    :return: completes incremental load based on job details and schema details for
    both partitioned and non-partitioned tables (overwrite conform master and append conform history)
    """
    logger.info("inside incremental load clm history")
    ctl_btch_id = ""
    da_database = job_details["Source_Crawler_DB_Name"]
    etl_database = job_details["Source_Crawler_DB_Name"]
    landing_table = job_details["Source_Crawler_Table_Name"]["Landing_Data_Object"][0]
    conform_table = job_details["Source_Crawler_Table_Name"]["Master_Data_Object"][0]
    src_offset_dict[landing_table] = incr_ingest_timestamp

    if 'MA_DataSync' in job_details.keys():
        maa_source = job_details["MA_DataSync"]
        logger.info(f"maa_source={maa_source}")
    else:
        maa_source = 'Y'

    isInventory = False
    if JOB_NAME in inventory_job_names:
        isInventory = True

    try:
        logger.info(f"Started reading from d&a landing for {landing_table}")
        # read incremental data from d&a and create spark data frame

        if maa_source.upper() == 'Y':
            bucket_env = db_env = landing_table.split("_")[2]
            db_tablename = "_".join(landing_table.split("_")[4:]).lower()
            if db_env == 'dev':
                db_env = '_dev'
            if db_env == 'qa':
                bucket_env = 'test'
                db_env = '_qa'
            if db_env == 'prod':
                db_env = ''

            domain = da_database.replace("_gov", "")
            madatasyncdatapath = f"s3://silverton-maa-raw-internal-data-{domain}-{bucket_env}/madatasync/oss_export{db_env}_v/{db_tablename}/incr_ingest_timestamp={incr_ingest_timestamp}"
            temp_df = spark.read.parquet(madatasyncdatapath)
            temp_df.printSchema()
            landing_incr_df = temp_df.withColumn("incr_ingest_timestamp", lit(incr_ingest_timestamp))
            logger.info(f"Reading from madatasync {landing_table} is completed: {landing_incr_df.count()}")
        else:
            landing_incr_df = spark.sql(
                f"select * from {da_database}.{landing_table} where incr_ingest_timestamp='{incr_ingest_timestamp}'"
            )
        logger.info(f"Completed reading from d&a landing for {landing_table}")
        #logger.info(f"Count of records read = {landing_incr_df.count()}")
        # get batch id from delta df
        # skipping ctl_btch_id for fhir control tables
        if landing_table.lower().find("fhir_cdo") == -1:
            ctl_btch_id = landing_incr_df.select("ctl_btch_id").first()["ctl_btch_id"]
        # convert incremental spark data frame to dynamic data frame
        landing_incr_dyf = DynamicFrame.fromDF(
            landing_incr_df, glue_context, "landing_incr_dyf"
        )
        # run update schema on incremental data frame
        landing_incr_dyf = update_schema(landing_incr_dyf, schema_details)
    except Exception as ex:
        common_util.update_job_table(
            job_details,
            start_time,
            0,
            0,
            "Failed",
            "E001",
            "Unable to read from table",
            datetime.now(timezone.utc),
            JOB_RUN_ID,
            src_offset_dict,
            BUCKET_NAME,
            glue_context,
            spark,
            ctl_btch_id,
            refresh_type=refresh_type,
        )

        logger.error(
            common_util.mattermost_logger_msg(
                "Error in {}: {}:{}".format(
                    inspect.currentframe().f_code.co_name, JOB_NAME, ex
                )
            )
        )
        raise Exception(
            "Unable to read from d&a landing table, table name : ", landing_table, ex
        )

    # if not isInventory:
    # try:
    #     # read full data from conform master
    #     logger.info(f'Started reading from Conform master for {conform_table}')
    #     conform_current_dyf = common_util.create_data_frame(etl_database, conform_table, ETL_CATALOG_ID,
    #                                                         glue_context, transformationCtx=False)
    #     logger.info(f'Completed reading from Conform master for {conform_table}')
    # except Exception as ex:
    #     common_util.update_job_table(job_details, start_time, 0, 0, 'Failed', 'E001', 'Unable to read from table',
    #                                  datetime.now(timezone.utc), JOB_RUN_ID, src_offset_dict, BUCKET_NAME,
    #                                  glue_context, spark, ctl_btch_id)
    #     logger.error(f'Unable to read from conform master table {conform_table}')
    #     raise Exception('Unable to read from conform master table, table name : ', conform_table, ex)

    if job_details["Partition_Key"]:
        try:
            incr_upd_df = landing_incr_dyf.toDF()
            # convert partition columns to string (since conform master contain them as string)
            for col in job_details["Partition_Key"]:
                incr_upd_df = incr_upd_df.withColumn(
                    col.lower(), incr_upd_df["{0}".format(col)].cast("string")
                )
            delta_dyf = DynamicFrame.fromDF(incr_upd_df, glue_context, "delta_dyf")
            # logger.info('Merge data frames started')
            # # merge data frame returns full master dynamic data frame and incremental dynamic data frame
            # # master dyf goes to conform master, incremental dyf goes to conform history
            # final_dyf, delta_upd_dyf = merge_data_frames(conform_current_dyf, delta_dyf,
            #                                              job_details['Joining_Condition'])
            # logger.info('Merge data frames complete')

            # below code can be ignored (test it before remove it)
            for i in schema_details:
                if i["name"] in job_details["Partition_Key"]:
                    i["tgt_type"] = "STRING"
            final_dyf = update_schema_after_merge(delta_dyf, schema_details)

        except Exception as ex:
            common_util.update_job_table(
                job_details,
                start_time,
                0,
                0,
                "Failed",
                "E003",
                "Unable to create final dataframe for clm history",
                datetime.now(timezone.utc),
                JOB_RUN_ID,
                src_offset_dict,
                BUCKET_NAME,
                glue_context,
                spark,
                ctl_btch_id,
                refresh_type=refresh_type,
            )

            logger.error(
                common_util.mattermost_logger_msg(
                    "Error in {}: {}:{}".format(
                        inspect.currentframe().f_code.co_name, JOB_NAME, ex
                    )
                )
            )
            raise Exception(
                "Unable to merge master and incremental for job: ",
                job_details["Job_Name"],
                ex,
            )
    else:
        try:

            # Below code make sure no null data types are there in data frames that we are going to write to s3
            # Since parquet format doesnt support null data types
            final_dyf = update_schema_after_merge(landing_incr_dyf, schema_details)

        except Exception as ex:
            common_util.update_job_table(
                job_details,
                start_time,
                0,
                0,
                "Failed",
                "E003",
                "Unable to create final dataframe for clm history",
                datetime.now(timezone.utc),
                JOB_RUN_ID,
                src_offset_dict,
                BUCKET_NAME,
                glue_context,
                spark,
                ctl_btch_id,
                refresh_type=refresh_type,
            )

            logger.error(
                common_util.mattermost_logger_msg(
                    "Error in {}: {}:{}".format(
                        inspect.currentframe().f_code.co_name, JOB_NAME, ex
                    )
                )
            )
            raise Exception(
                "Unable to merge master and incremental for job: ",
                job_details["Job_Name"],
                ex,
            )

    target_count = update_history(final_dyf.toDF(), job_details, False, ctl_btch_id)

    common_util.update_job_table(
        job_details,
        start_time,
        landing_incr_dyf.count(),
        target_count,
        "Success",
        "",
        "",
        datetime.now(),
        JOB_RUN_ID,
        src_offset_dict,
        BUCKET_NAME,
        glue_context,
        spark,
        ctl_btch_id,
        refresh_type=refresh_type,
    )


def incremental_load_clm_master(job_details, schema_details):
    """

    :param job_details:
    :param schema_details:
    :return: completes incremental load based on job details and schema details for
    both partitioned and non-partitioned tables (overwrite conform master and append conform history)
    """
    logger.info("inside incremental load clm master")
    ctl_btch_id = ""
    da_database = job_details["Source_Crawler_DB_Name"]
    etl_database = job_details["Source_Crawler_DB_Name"]
    landing_table = job_details["Source_Crawler_Table_Name"]["Landing_Data_Object"][0]
    conform_table = job_details["Source_Crawler_Table_Name"]["Master_Data_Object"][0]
    src_offset_dict[landing_table] = incr_ingest_timestamp

    if 'MA_DataSync' in job_details.keys():
        maa_source = job_details["MA_DataSync"]
        logger.info(f"maa_source={maa_source}")
    else:
        maa_source = 'Y'

    isInventory = False
    if JOB_NAME in inventory_job_names:
        isInventory = True

    try:
        logger.info(f"Started reading from d&a landing for {landing_table}")
        # read incremental data from d&a and create spark data frame

        if maa_source.upper() == 'Y':
            bucket_env = db_env = landing_table.split("_")[2]
            db_tablename = "_".join(landing_table.split("_")[4:]).lower()
            if db_env == 'dev':
                db_env = '_dev'
            if db_env == 'qa':
                bucket_env = 'test'
                db_env = '_qa'
            if db_env == 'prod':
                db_env = ''

            domain = da_database.replace("_gov", "")
            madatasyncdatapath = f"s3://silverton-maa-raw-internal-data-{domain}-{bucket_env}/madatasync/oss_export{db_env}_v/{db_tablename}/incr_ingest_timestamp={incr_ingest_timestamp}"
            temp_df = spark.read.parquet(madatasyncdatapath)
            temp_df.printSchema()
            landing_incr_df = temp_df.withColumn("incr_ingest_timestamp", lit(incr_ingest_timestamp))
            logger.info(f"Reading from madatasync {landing_table} is completed: {landing_incr_df.count()}")
        else:
            landing_incr_df = spark.sql(
                f"select * from {da_database}.{landing_table} where incr_ingest_timestamp='{incr_ingest_timestamp}'"
            )
        logger.info(f"Completed reading from d&a landing for {landing_table}")
        # get batch id from delta df
        ctl_btch_id = landing_incr_df.select("ctl_btch_id").first()["ctl_btch_id"]
        # convert incremental spark data frame to dynamic data frame
        landing_incr_dyf = DynamicFrame.fromDF(
            landing_incr_df, glue_context, "landing_incr_dyf"
        )
        # run update schema on incremental data frame
        landing_incr_dyf = update_schema(landing_incr_dyf, schema_details)
    except Exception as ex:
        common_util.update_job_table(
            job_details,
            start_time,
            0,
            0,
            "Failed",
            "E001",
            "Unable to read from table",
            datetime.now(timezone.utc),
            JOB_RUN_ID,
            src_offset_dict,
            BUCKET_NAME,
            glue_context,
            spark,
            ctl_btch_id,
            refresh_type=refresh_type,
        )

        logger.error(
            common_util.mattermost_logger_msg(
                "Error in {}: {}:{}".format(
                    inspect.currentframe().f_code.co_name, JOB_NAME, ex
                )
            )
        )
        raise Exception(
            "Unable to read from d&a landing table, table name : ", landing_table, ex
        )

    # if not isInventory:
    try:
        # read full data from conform master
        logger.info(f"Started reading from Conform master for {conform_table}")
        conform_current_dyf = common_util.create_data_frame(
            etl_database,
            conform_table,
            ETL_CATALOG_ID,
            glue_context,
            transformationCtx=False,
        )
        logger.info(f"Completed reading from Conform master for {conform_table}")
    except Exception as ex:
        common_util.update_job_table(
            job_details,
            start_time,
            0,
            0,
            "Failed",
            "E001",
            "Unable to read from table",
            datetime.now(timezone.utc),
            JOB_RUN_ID,
            src_offset_dict,
            BUCKET_NAME,
            glue_context,
            spark,
            ctl_btch_id,
            refresh_type=refresh_type,
        )

        logger.error(
            common_util.mattermost_logger_msg(
                "Error in {}: {}:{}".format(
                    inspect.currentframe().f_code.co_name, JOB_NAME, ex
                )
            )
        )
        raise Exception(
            "Unable to read from conform master table, table name : ", conform_table, ex
        )

    delta_count = 0
    if job_details["Partition_Key"]:
        try:
            incr_upd_df = landing_incr_dyf.toDF()
            # convert partition columns to string (since conform master contain them as string)
            for col in job_details["Partition_Key"]:
                incr_upd_df = incr_upd_df.withColumn(
                    col.lower(), incr_upd_df["{0}".format(col)].cast("string")
                )
            delta_dyf = DynamicFrame.fromDF(incr_upd_df, glue_context, "delta_dyf")
            logger.info("Merge data frames started")
            # merge data frame returns full master dynamic data frame and incremental dynamic data frame
            # master dyf goes to conform master, incremental dyf goes to conform history
            # final_dyf, delta_upd_dyf = merge_data_frames(
            #     conform_current_dyf, delta_dyf, job_details["Joining_Condition"]
            # )

            final_dyf = conform_current_dyf.mergeDynamicFrame(
                delta_dyf, [job_details["Joining_Condition"]]
            )

            # logger.info(f"Conform current count: {conform_current_dyf.count()}")

            # logger.info("Merge data frames complete")
            delta_count = delta_dyf.count()

            # if delta_count > 0:
            #     ddf = delta_dyf.toDF()
            #     logger.info(f"Delta dyf count: {delta_count}")
            #     di = ddf.where(ddf.CTL_ETL_DML_FLG == "I").count()
            #     dd = ddf.where(ddf.CTL_ETL_DML_FLG == "D").count()
            #     du = ddf.where(ddf.CTL_ETL_DML_FLG == "U").count()
            #     logger.info(f"Delta dyf I count: {di}")
            #     logger.info(f"Delta dyf U count: {du}")
            #     logger.info(f"Delta dyf D count: {dd}")

            # logger.info(f"Merged final count: {final_dyf.count()}")
            # fdf = final_dyf.toDF()
            # fi = fdf.where(fdf.CTL_ETL_DML_FLG == "I").count()
            # fd = fdf.where(fdf.CTL_ETL_DML_FLG == "D").count()
            # fu = fdf.where(fdf.CTL_ETL_DML_FLG == "U").count()
            # logger.info(f"Final dyf I count: {fi}")
            # logger.info(f"Final dyf U count: {fu}")
            # logger.info(f"Final dyf D count: {fd}")

            # below code can be ignored (test it before remove it)
            for i in schema_details:
                if i["name"] in job_details["Partition_Key"]:
                    i["tgt_type"] = "STRING"
            final_dyf = update_schema_after_merge(final_dyf, schema_details)

        except Exception as ex:
            common_util.update_job_table(
                job_details,
                start_time,
                0,
                0,
                "Failed",
                "E003",
                "Unable to merge master and incremental",
                datetime.now(timezone.utc),
                JOB_RUN_ID,
                src_offset_dict,
                BUCKET_NAME,
                glue_context,
                spark,
                ctl_btch_id,
                refresh_type=refresh_type,
            )
            logger.error(
                common_util.mattermost_logger_msg(
                    "Error in {}: {}:{}".format(
                        inspect.currentframe().f_code.co_name, JOB_NAME, ex
                    )
                )
            )
            raise Exception(
                "Unable to merge master and incremental for job: ",
                job_details["Job_Name"],
                ex,
            )

        try:
            logger.info("Started writing to conform master temp")
            s3_temp_path = f"{job_details['Target_S3_Folder_Name']['Master']}/temp"
            final_dyf.toDF().write.partitionBy(job_details["Partition_Key"]).mode(
                "overwrite"
            ).format("parquet").option("compression", "snappy").save(s3_temp_path)

            # from temp copy to actual s3 path
            common_util.update_conform_master(s3_temp_path)

            logger.info("Completed writing to conform master")
        except Exception as ex:
            common_util.update_job_table(
                job_details,
                start_time,
                0,
                0,
                "Failed",
                "E002",
                "Unable to write to target object",
                datetime.now(timezone.utc),
                JOB_RUN_ID,
                src_offset_dict,
                BUCKET_NAME,
                glue_context,
                spark,
                ctl_btch_id,
                refresh_type=refresh_type,
            )
            logger.error(
                common_util.mattermost_logger_msg(
                    "Error in {}: {}:{}".format(
                        inspect.currentframe().f_code.co_name, JOB_NAME, ex
                    )
                )
            )
            raise Exception(
                "Unable to write to target: ",
                job_details["Target_S3_Folder_Name"]["Master"],
                ex,
            )
    else:
        try:
            logger.info("Merge data frames started")
            # merge data frame returns full master dynamic data frame and incremental dynamic data frame
            # master dyf goes to conform master, incremental dyf goes to conform history
            final_dyf = conform_current_dyf.mergeDynamicFrame(
                landing_incr_dyf, [job_details["Joining_Condition"]]
            )

            # logger.info(f"Conform current count: {conform_current_dyf.count()}")

            delta_count = landing_incr_dyf.count()
            # if delta_count > 0:
            #     ddf = landing_incr_dyf.toDF()
            #     logger.info(f"landing_incr_dyf count: {delta_count}")
            #     di = ddf.where(ddf.CTL_ETL_DML_FLG == "I").count()
            #     dd = ddf.where(ddf.CTL_ETL_DML_FLG == "D").count()
            #     du = ddf.where(ddf.CTL_ETL_DML_FLG == "U").count()
            #     logger.info(f"landing_incr_dyf dyf I count: {di}")
            #     logger.info(f"landing_incr_dyf dyf U count: {du}")
            #     logger.info(f"landing_incr_dyf dyf D count: {dd}")

            # logger.info(f"final_dyf count: {final_dyf.count()}")
            # fdf = final_dyf.toDF()
            # fi = fdf.where(fdf.CTL_ETL_DML_FLG == "I").count()
            # fd = fdf.where(fdf.CTL_ETL_DML_FLG == "D").count()
            # fu = fdf.where(fdf.CTL_ETL_DML_FLG == "U").count()
            # logger.info(f"Final dyf I count: {fi}")
            # logger.info(f"Final dyf U count: {fu}")
            # logger.info(f"Final dyf D count: {fd}")

            logger.info("Merge data frames complete")
            final_dyf.toDF()
            # Below code make sure no null data types are there in data frames that we are going to write to s3
            # Since parquet format doesnt support null data types
            final_dyf = update_schema_after_merge(final_dyf, schema_details)
            # delta_upd_dyf = update_schema_after_merge(delta_upd_dyf, schema_details)

        except Exception as ex:
            common_util.update_job_table(
                job_details,
                start_time,
                0,
                0,
                "Failed",
                "E003",
                "Unable to merge master and incremental",
                datetime.now(timezone.utc),
                JOB_RUN_ID,
                src_offset_dict,
                BUCKET_NAME,
                glue_context,
                spark,
                ctl_btch_id,
                refresh_type=refresh_type,
            )
            logger.error(
                "Unable to merge master and incremental for job : {0}".format(
                    job_details["Job_Name"]
                )
            )
            raise Exception(
                "Unable to merge master and incremental for job: ",
                job_details["Job_Name"],
                ex,
            )

        try:
            logger.info("Started writing to conform clm master temp")
            # write to temp directory
            s3_temp_path = f"{job_details['Target_S3_Folder_Name']['Master']}/temp"
            final_dyf.toDF().write.mode("overwrite").format("parquet").option(
                "compression", "snappy"
            ).save(s3_temp_path)

            # from temp copy to actual s3 path
            common_util.update_conform_master(s3_temp_path)

            logger.info("Completed writing to conform master")
        except Exception as ex:
            common_util.update_job_table(
                job_details,
                start_time,
                0,
                0,
                "Failed",
                "E002",
                "Unable to write to target object",
                datetime.now(timezone.utc),
                JOB_RUN_ID,
                src_offset_dict,
                BUCKET_NAME,
                glue_context,
                spark,
                ctl_btch_id,
                refresh_type=refresh_type,
            )
            logger.error(
                common_util.mattermost_logger_msg(
                    "Error in {}: {}:{}".format(
                        inspect.currentframe().f_code.co_name, JOB_NAME, ex
                    )
                )
            )
            raise Exception(
                "Unable to write to target: ",
                job_details["Target_S3_Folder_Name"]["Master"],
                ex,
            )

    common_util.update_job_table(
        job_details,
        start_time,
        landing_incr_dyf.count(),
        delta_count,
        "Success",
        "",
        "",
        datetime.now(),
        JOB_RUN_ID,
        src_offset_dict,
        BUCKET_NAME,
        glue_context,
        spark,
        ctl_btch_id,
        refresh_type=refresh_type,
    )


def update_history(history_df, job_details, isInventory: bool, ctl_btch_id):
    """

    :param ctl_btch_id:
    :param isInventory:
    :param job_details:
    :param history_df: delta dynamic frame
    :return: completes writing history file
    """
    s3_path = job_details["Target_S3_Folder_Name"]["History"]
    try:
        total_rec_cnt = 0
        logger.info("started writing to conform history")
        if isInventory:
            history_df.coalesce(1).write.partitionBy("incr_ingest_timestamp").mode(
                "overwrite"
            ).format("json").save(s3_path)
        else:
            delete_rec_cnt = (
                                history_df.select("ctl_etl_dml_flg")
                                .filter(col("ctl_etl_dml_flg") == "D")
                                .count()
                            )
            total_rec_cnt = history_df.count()
            if (delete_rec_cnt / total_rec_cnt) > 0.1:
                logger.warning(
                    common_util.mattermost_logger_msg(
                        "Warning in {}: {}:{}".format(
                            inspect.currentframe().f_code.co_name,
                            JOB_NAME,
                            "Delete records more than 10% of total load",
                        )
                    )
                )

            history_df.write.partitionBy("incr_ingest_timestamp").mode(
                "overwrite"
            ).format("parquet").option("compression", "snappy").save(s3_path)

        logger.info("completed writing to conform history")

        return total_rec_cnt

    except Exception as ex:
        common_util.update_job_table(
            job_details,
            start_time,
            0,
            0,
            "Failed",
            "E002",
            "Write to conform history failed",
            datetime.now(timezone.utc),
            JOB_RUN_ID,
            src_offset_dict,
            BUCKET_NAME,
            glue_context,
            spark,
            ctl_btch_id,
            refresh_type=refresh_type,
        )
        logger.error(
            common_util.mattermost_logger_msg(
                "Error in {}: {}:{}".format(
                    inspect.currentframe().f_code.co_name, JOB_NAME, ex
                )
            )
        )
        raise Exception("Unable to write to target: ", s3_path, ex)


def no_records_received(job_details):
    # insert record into jobexecution table
    logger.info("Zero records received from D&A")
    ctl_btch_id = ""
    common_util.update_job_table(
        job_details,
        start_time,
        0,
        0,
        "Completed",
        "E006",
        "Zero records received from D&A",
        datetime.now(timezone.utc),
        JOB_RUN_ID,
        src_offset_dict,
        BUCKET_NAME,
        glue_context,
        spark,
        ctl_btch_id,
        refresh_type=refresh_type,
    )

def check_crawler_status(crawler_name):
    logger.info("Check crawler status")
    try:
        is_running = "Y"
        crawl_response = glue_client.get_crawler(
            Name=crawler_name
        )
        if crawl_response["ResponseMetadata"]["HTTPStatusCode"] != 200:
            raise Exception(
                f"Crawler trigger response returned http status code other than 200 {crawler_name}"
            )
        logger.info(f"crawl_response: {crawl_response}")

        if crawl_response["Crawler"]["State"] == 'READY':
            is_running = "N"

        return is_running

    except Exception as ex:
        raise Exception("Unable to get to crawler_status: ", ex)

def process_landing_to_conform():
    """

    :return: completes moving data from landing to conform
    """
    try:
        logger.info(
            "Started {JOB} at {TIME}".format(
                JOB=JOB_NAME, TIME=datetime.now(timezone.utc)
            )
        )
        logger.info(f"processing data for timestamp {incr_ingest_timestamp}")
        # if JOB_NAME.lower() == "job_gov_conform_oss_cdo_phrm_clm_master": #2022FEB21: hold claim jobs which updates master tables
        if JOB_NAME.lower() in ["job_gov_conform_oss_cdo_phrm_clm_master",
                                "job_gov_conform_oss_cdo_med_clm_hdr_master",
                                "job_gov_conform_oss_cdo_med_clm_dtl_master",
                                "job_gov_conform_oss_cdo_med_clm_remit_hdr_master",
                                "job_gov_conform_oss_cdo_med_clm_remit_dtl_master",
                                "job_gov_conform_oss_cdo_med_clm_chk_dtl_master",
                                "job_gov_conform_oss_cdo_med_clm_adj_rsn_dtl_master",
                                "job_gov_conform_oss_cdo_med_clm_edit_hdr_master",
                                "job_gov_conform_oss_cdo_med_clm_edit_dtl_master",
                                "job_gov_conform_oss_cdo_med_clm_adj_rsn_hdr_master",
                                "job_gov_conform_oss_cdo_clm_icd_proc_cd_master",
                                "job_gov_conform_oss_cdo_clm_diag_cd_master",
                                "job_gov_conform_oss_cdo_clm_ln_diag_cd_master"]:
            logger.info("Exiting job_gov_conform_oss_cdo_phrm_clm_master and Medical_CLM_master as a temp fix")
            return None
        job_details = {}
        with open("config.json") as json_file:
            for i in json_file:
                job_dict = json.loads(i)
                if job_dict["Job_Name"] == JOB_NAME:
                    job_details = job_dict

        logger.info("job details: {0}".format(job_details))

        if len(job_details) != 0:
            if upd_record_count == "0":
                no_records_received(job_details)
                return

            SourceSchema = json.loads(job_details["Source_Data_Object_Schema_Text"])
            TargetSchema = json.loads(job_details["Target_Data_Object_Schema_Text"])
            schema_details = parse_schema(SourceSchema, TargetSchema)
            # crawler details
            # if JOB_NAME.lower().find("master") == -1: # master word not found
            #     crawler_prefixes = ['crawler_history_'] if ( (JOB_NAME in inventory_job_names) or (JOB_NAME.lower().find("clm") != -1) ) else ['crawler_','crawler_history_']
            #     crawlers = [JOB_NAME.replace('job_gov_conform_', prefix) for prefix in crawler_prefixes]
            # else:
            #     crawler_prefixes = ['crawler_']
            #     JOB_NAME1 = JOB_NAME.replace('_master','')
            #
            #     crawlers = [JOB_NAME1.replace('job_gov_conform_', prefix) for prefix in crawler_prefixes]

            if JOB_NAME.lower().find("master") == -1:  # master word not found
                logger.info("History Job")
                crawler_prefixes = ["crawler_history_"]
                crawlers = [
                    JOB_NAME.replace("job_gov_conform_", prefix)
                    for prefix in crawler_prefixes
                ]

            else:
                logger.info("Master Job")

            if JOB_NAME in inventory_job_names:
                crawlers.append("crawler_metadata_awsjobexecution")
            ends_with = ".json" if JOB_NAME in inventory_job_names else ".parquet"
            # update job execution table add entry as job started
            common_util.update_job_table(
                job_details,
                datetime.now(timezone.utc),
                0,
                0,
                "Started",
                "",
                "",
                datetime.now(timezone.utc),
                JOB_RUN_ID,
                {},
                BUCKET_NAME,
                glue_context,
                spark,
                refresh_type=refresh_type,
            )

            logger.info(f"received refresh type: {refresh_type}")

            if refresh_type.lower() == "full":
                #clm control table full load is also considered as incr as no master data is maintained
                if ( JOB_NAME.lower().find("fhir_cdo") != -1 ) :
                    incremental_load_clm_history(job_details, schema_details)
                elif ( JOB_NAME.lower().find("fhir_ctl") != -1 ):
                    incremental_load(job_details, schema_details)
                else:
                    full_load(job_details, schema_details)
            else:
                logger.info("incremental load started")
                if JOB_NAME.lower().find("clm") == -1:  # not a clm cdo
                    incremental_load(job_details, schema_details)
                else:
                    if JOB_NAME.lower().find("master") == -1:  # history word not found
                        incremental_load_clm_history(job_details, schema_details)
                    else:
                        incremental_load_clm_master(job_details, schema_details)

                logger.info("incremental load complete")

            # starting crawlers

            database = job_details["Source_Crawler_DB_Name"]

            if JOB_NAME.lower().find("master") == -1:  # master word not found
                if (
                    JOB_NAME in inventory_job_names
                ):  # do not prepend history_ for inventory table name
                    table = job_details["Source_Crawler_Table_Name"][
                        "Master_Data_Object"
                    ][0]
                else:
                    database = database + "_history"
                    table = (
                        "history_"
                        + job_details["Source_Crawler_Table_Name"][
                            "Master_Data_Object"
                        ][0]
                    )
                logger.info("History Job")
                add_new_partition(
                    glue_client=glue_client,
                    database_name=database,
                    table_name=table,
                    partition=incr_ingest_timestamp,
                )

            else:
                logger.info("Master Job")

            if JOB_NAME in inventory_job_names:
                is_crawler_running = check_crawler_status("crawler_metadata_awsjobexecution")
                logger.info(f"is_crawler_running: {is_crawler_running}")
                if is_crawler_running == "N":
                    common_util.trigger_crawler("crawler_metadata_awsjobexecution")
                    logger.info("completed crawlers for awsjobexecution")
                else:
                    logger.info("crawler for awsjobexecution is already running, skipping the run")

            logger.info(
                "Completed {JOB} at {TIME}".format(
                    JOB=JOB_NAME, TIME=datetime.now(timezone.utc)
                )
            )
            job.commit()
        else:
            logger.error(
                common_util.mattermost_logger_msg(
                    "Error in {}: {}:{}".format(
                        inspect.currentframe().f_code.co_name,
                        JOB_NAME,
                        "No job details found in config.json file",
                    )
                )
            )
            raise Exception("Error: No job details found in config.json file")
    except Exception as ex:
        logger.error(
            common_util.mattermost_logger_msg(
                "Error in {}: {}:{}".format(
                    inspect.currentframe().f_code.co_name, JOB_NAME, ex
                )
            )
        )
        raise Exception("Exception while moving data from landing to conform : ", ex)


process_landing_to_conform()
