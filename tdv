
import pytest
from unittest.mock import patch, MagicMock
from db_config_create import Db_Config_Create  # Change this if your file is named differently
import json


@pytest.fixture
def mock_env_vars():
    with patch("db_config_create.getResolvedOptions") as mock_get_args:
        mock_get_args.return_value = {
            "OSS_ENV": "dev",
            "DATABASE_NAME": "test_db_V",
            "TABLE_NAME": "test_table",
            "SERVER": "td.test.com",
            "secret_name": "mysecret",
            "BUCKET_NAME": "my-bucket",
            "JOB_RUN_ID": "job-123"
        }
        yield


@pytest.fixture
def mock_aws_services():
    with patch("db_config_create.boto3.resource") as mock_resource, \
         patch("db_config_create.boto3.session.Session") as mock_session:

        # Mock SecretsManager
        mock_client = MagicMock()
        mock_client.get_secret_value.return_value = {
            "SecretString": json.dumps({"username": "admin", "password": "adminpass"})
        }
        mock_session.return_value.client.return_value = mock_client

        # Mock S3 and DynamoDB
        mock_ddb = MagicMock()
        mock_ddb.Table.return_value = MagicMock()
        mock_s3_obj = MagicMock()
        mock_resource.return_value.Object.return_value = mock_s3_obj
        mock_resource.return_value.Table.return_value = MagicMock()

        yield mock_resource, mock_session, mock_s3_obj


@pytest.fixture
def mock_spark_session():
    with patch("db_config_create.SparkSession.builder.getOrCreate") as mock_spark:
        mock_session = MagicMock()
        mock_df = MagicMock()
        mock_df.count.return_value = 2
        mock_df.toPandas.return_value = MagicMock(
            sort_values=lambda by: MagicMock(
                __getitem__=lambda self, key: MagicMock(to_list=lambda: ["col1 INT", "col2 STRING"]),
                index=[0, 1],
                __getitem__=lambda self, idx: {
                    0: "col1 INT",
                    1: "col2 STRING"
                }[idx]
            )
        )
        mock_session.read.format.return_value.option.return_value.option.return_value.option.return_value.load.return_value = mock_df
        mock_spark.return_value = mock_session
        yield mock_spark


@pytest.fixture
def mock_teradata():
    with patch("db_config_create.teradatasql.connect") as mock_td:
        mock_cursor = MagicMock()
        mock_td.return_value.cursor.return_value = mock_cursor
        yield mock_td, mock_cursor


def test_get_tdv_creds(mock_env_vars, mock_aws_services, mock_spark_session):
    obj = Db_Config_Create()
    username, password = obj.get_tdv_creds()
    assert username == "admin"
    assert password == "adminpass"


def test_update_audit_table(mock_env_vars, mock_aws_services, mock_spark_session):
    obj = Db_Config_Create()
    obj.update_audit_table("job-123", "test_db", "test_table", "Success", "")
    audit_call = obj.audit_table.update_item.call_args[1]
    assert audit_call["ExpressionAttributeValues"][":Run_Status"] == "Success"


def test_write_to_s3_success(mock_env_vars, mock_aws_services, mock_spark_session, mock_teradata):
    obj = Db_Config_Create()
    obj.write_to_s3()
    # Check that S3 put was called for both TXT and JSON
    mock_s3 = mock_aws_services[2]
    assert mock_s3.put.call_count == 2


def test_write_to_s3_fail_secrets(mock_env_vars, mock_spark_session):
    with patch("db_config_create.boto3.session.Session") as mock_session:
        mock_session.return_value.client.return_value.get_secret_value.side_effect = Exception("Secrets error")
        with pytest.raises(Exception):
            obj = Db_Config_Create()
            obj.write_to_s3()


def test_write_to_s3_fail_audit(mock_env_vars, mock_aws_services, mock_spark_session, mock_teradata):
    obj = Db_Config_Create()
    obj.audit_table.update_item.side_effect = Exception("DynamoDB error")
    with pytest.raises(Exception):
        obj.write_to_s3()
