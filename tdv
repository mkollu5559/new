
import sys
from unittest.mock import MagicMock

# Manually mock awsglue.utils.getResolvedOptions with real return values
mock_get_resolved_options = lambda argv, keys: {
    "OSS_ENV": "dev",
    "DATABASE_NAME": "test_db_V",
    "TABLE_NAME": "test_table",
    "SERVER": "td.test.com",
    "secret_name": "mysecret",
    "BUCKET_NAME": "my-bucket",
    "JOB_RUN_ID": "job-123"
}

# Inject into sys.modules before importing the main module
mock_awsglue_utils = MagicMock()
mock_awsglue_utils.getResolvedOptions = mock_get_resolved_options
sys.modules['awsglue'] = MagicMock()
sys.modules['awsglue.utils'] = mock_awsglue_utils

# Now safe to import
import pytest
from unittest.mock import patch, MagicMock
import json
from db_config_create import Db_Config_Create


@pytest.fixture
def mock_aws_services():
    with patch("db_config_create.boto3.resource") as mock_resource, \
         patch("db_config_create.boto3.session.Session") as mock_session:

        # Mock SecretsManager
        mock_client = MagicMock()
        mock_client.get_secret_value.return_value = {
            "SecretString": json.dumps({"username": "admin", "password": "adminpass"})
        }
        mock_session.return_value.client.return_value = mock_client

        # Mock S3 and DynamoDB
        mock_ddb = MagicMock()
        mock_ddb.Table.return_value = MagicMock()
        mock_s3_obj = MagicMock()
        mock_resource.return_value.Object.return_value = mock_s3_obj
        mock_resource.return_value.Table.return_value = MagicMock()

        yield mock_resource, mock_session, mock_s3_obj


@pytest.fixture
def mock_spark_session():
    with patch("db_config_create.SparkSession.builder.getOrCreate") as mock_spark:
        mock_session = MagicMock()
        mock_df = MagicMock()
        mock_df.count.return_value = 2

        # Mock the toPandas() DataFrame
        mock_pandas_df = MagicMock()
        mock_pandas_df.index = [0, 1]
        mock_pandas_df.__getitem__.side_effect = lambda key: {
            "COL_DATATYPE": ["col1 INT", "col2 STRING"]
        }[key]
        mock_pandas_df.sort_values.return_value = mock_pandas_df
        mock_pandas_df["COL_DATATYPE"].to_list = lambda: ["col1 INT", "col2 STRING"]

        mock_df.toPandas.return_value = mock_pandas_df
        mock_session.read.format.return_value.option.return_value.option.return_value.option.return_value.load.return_value = mock_df
        mock_spark.return_value = mock_session
        yield mock_spark


@pytest.fixture
def mock_teradata():
    with patch("db_config_create.teradatasql.connect") as mock_td:
        mock_cursor = MagicMock()
        mock_td.return_value.cursor.return_value = mock_cursor
        yield mock_td, mock_cursor


def test_get_tdv_creds(mock_aws_services, mock_spark_session):
    obj = Db_Config_Create()
    username, password = obj.get_tdv_creds()
    assert username == "admin"
    assert password == "adminpass"


def test_update_audit_table(mock_aws_services, mock_spark_session):
    obj = Db_Config_Create()
    obj.update_audit_table("job-123", "test_db", "test_table", "Success", "")
    audit_call = obj.audit_table.update_item.call_args[1]
    assert audit_call["ExpressionAttributeValues"][":Run_Status"] == "Success"


def test_write_to_s3_success(mock_aws_services, mock_spark_session, mock_teradata):
    obj = Db_Config_Create()
    obj.write_to_s3()
    # Check that S3 put was called for both TXT and JSON
    mock_s3 = mock_aws_services[2]
    assert mock_s3.put.call_count == 2


def test_write_to_s3_fail_secrets(mock_spark_session):
    with patch("db_config_create.boto3.session.Session") as mock_session:
        mock_session.return_value.client.return_value.get_secret_value.side_effect = Exception("Secrets error")
        with pytest.raises(Exception):
            obj = Db_Config_Create()
            obj.write_to_s3()


def test_write_to_s3_fail_audit(mock_aws_services, mock_spark_session, mock_teradata):
    obj = Db_Config_Create()
    obj.audit_table.update_item.side_effect = Exception("DynamoDB error")
    with pytest.raises(Exception):
        obj.write_to_s3()
